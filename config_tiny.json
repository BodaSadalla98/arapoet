{
    "model_name_or_path": "aubmindlab/aragpt2-large",
    "model_type": "gpt2",
    "train_file": "tiny_data.txt",
    "block_size": 128,
    "preprocessing_num_workers": 32,
    "output_dir": "output_tiny",
    "do_train": "true",
    "do_eval": "true",
    "overwrite_output_dir": "true",
    "num_train_epochs": 2.0,
    "per_device_train_batch_size": 16,
    "per_device_eval_batch_size": 16,
    "save_strategy": "epoch",
    "evaluation_strategy": "epoch",
    "max_train_samples": 10
}