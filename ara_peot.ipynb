{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman.atef\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tiny_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59834/187719889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tiny_data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tiny_data.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('tiny_data.txt', 'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097608\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عيناك غابتا نخيل ساعة السحر او شرفتان راح يناي عنهما القمر عيناك حين تبسمان تورق الكروم وترقص الاضواء كالاقمار في نهر يرجه المجذاف وهنا ساعة السحر كانما تنبض في غوريهما النجوم وتغرقان في ضباب من اسي شفيف كالبحر سرح اليدين فوقه المساء دفء الشتاء فيه وارتعاشة الخريف والموت والميلاد والظلام والضياء فتستفيق ملء روحي رعشة البكاء ونشوة وحشية تعانق السماء كنشوة الطفل اذا خاف من القمر كان اقواس السحاب تشرب الغيوم وقطرة فقطرة تذوب في المطر وكركر الاطفال في عراءش الكروم ودغدغت صمت العصافير علي الشجر انشودة المطر مطر مطر مطر تثاءب المساء والغيوم ما تزال تسح ما تسح من دموعها الثقال كان طفلا بات يهذي قبل ان ينام بان امه  التي افاق منذ عام فلم يجدها ثم حين لج في السءال قالوا له بعد غد تعود  لا بد ان تعود وان تهامس الرفاق انها هناك في جانب التل تنام نومة الحود تسف من ترابها وتشرب المطر كان صيادا حزينا يجمع الشباك ويلعن المياه والقدر وينثر الغناء حيث يافل القمر مطر مطر اتعلمين اي حزن يبعث المطر وكيف تنشج المزاريب اذا انهمر وكيف يشعر الوحيد فيه بالضياع بلا انتهاء  كالدم المراق كالجياع كالحب كالاطفال كالموتي  هو المطر ومقلتاك بي تطيفان مع المطر وعبر امواج الخليج تمسح البروق سواحل العراق بالنجوم والمحار كانها تهم بالشروق فيسحب اليل عليها من دم دثار اصيح بالخليج  يا خليج يا واهب الءلء والمحار والردي  فيرجع الصدي كانه النشيج  يا خليج يا واهب المحار والردي  اكاد اسمع العراق يذخر الرعود ويخزن البروق في السهول والجبال حتي اذا ما فض عنها ختمها الرجال لم ترك الرياح من ثمود في الواد من اثر اكاد اسمع النخيل يشرب المطر واسمع القري تءن والمهاجرين يصارعون بالمجاذيف وبالقلوع عواصف الخليج والرعود منشدين  مطر مطر مطر وفي العراق جوع وينثر الغلال فيه موسم الحصاد لتشبع الغربان والجراد وتطحن الشوان والحجر رحي تدور في الحقول حولها بشر مطر مطر مطر وكم ذرفنا ليلة الرحيل من دموع ثم اعتلنا  خوف ان نلام  بالمطر مطر مطر ومنذ ان كنا صغارا كانت السماء تغيم في الشتاء ويهطل المطر وكل عام  حين يعشب الثري  نجوع ما مر عام والعراق ليس فيه جوع مطر مطر مطر في كل قطرة من المطر حمراء او صفراء من اجنة الزهر وكل دمعة من الجياع والعراة وكل قطرة تراق من دم العبيد فهي ابتسام في انتظار مبسم جديد او حلمة توردت علي فم الوليد في عالم الغد الفتي واهب الحياة مطر مطر مطر سيعشب العراق بالمطر  اصيح بالخليج  يا خليج يا واهب الءلء والمحار والردي  فيرجع الصدي كانه النشيج  يا خليج يا واهب المحار والردي  وينثر الخليج من هباته الكثار علي الرمال رغوه الاجاج والمحار وما تبقي من عظام باءس غريق من المهاجرين ظل يشرب الردي من لجة الخليج والقرار وفي العراق الف افعي تشرب الرحيق من زهرة يربها الفرات بالندي واسمع الصدي يرن في الخليج  مطر مطر مطر في كل قطرة من المطر حمراء او صفراء من اجنة الزهر وكل دمعة من الجياع والعراة وكل قطرة تراق من دم العبيد فهي ابتسام في انتظار مبسم جديد او حلمة توردت علي فم الوليد في عالم الغد الفتي واهب الحياة  ويهطل المطر \n",
      " انا لا ازال و في يدي قدحي ياليل اين تفرق الشرب ما زلت اشربها و اشربها حتي ترنح افقك الرحب الشرق عفر بالضباب فما يبدو فاين سناك يا غرب ما لنجوم غرقن من سام في ضوءهن و كادت الشهب انا لا ازال و في يدي قدحي ياليل اين تفرق الشرب  الحان بالشهوات مصطخب حتي يكاد بهن ينهار و كان مصاحبيه من ضرج كفان مدهما لي العار كفان بل ثغران قد صبغا بدم تدفق منه تيار كاسان ملءهما طلي عصرت من مهجتين رماهما الحب او مخلبان عليهما مزق حمراء تزعم انها قلب  الخمر جمعت الدهور  ومافيهن بين جوانب الحان ياويحها اسكرت ام سكرتام نحن في السكرات سيان رمت العوالم والدهور علي ثغري وفوق يدي واجفاني كفي تمد فما تناولني كاسا لعيني خمرها نهب واصافح الدنيا فياعجبا البعد لان واعرض القرب  يا ليل اين تطوف بي قدمي في اي منعرج من الظلم تلك السبيل اكاد اعرفها بالامس خاصر طيفها حلمي هي غمد خنجرك الرهيب و قد جردته و مسحت عنه دمي تلك السبيل علي جوانبها تمزق الخطوات او تكبو تثاءب الاجساد جاءعة فيها كما يتثاءب الذءب حسناء يلهب عريها ظماي فاكاد اشرب ذلك العريا و اكاد احطمه فتحطمني عينان جاءعتان كالدنيا غرست يد الحمي علي فمها زهرا طوي شهواتها طيا ان فتحته بحرها شفة سكري يعربد فوقها ندب رقص الهيب علي كماءمه و مشي الطلاء يهزه الوثب عين يرنح هدبها نفسي وفم يقطع همسه الداء ويد علي كتفي مجلجلة رباه ويك اتلك حواء لا كنت ادمها و لا لفحت فردوسي الخمري صحراء صوت النعاس يرن في افقي فتذوب ناعسة به السحب ان الفراش يقيك ياقدمي سوء العثار اذا دجي درب  انا حاءر متوجف قلق كالظل بين جوانب البحر المد قربني الي شبحي والان تبعدني يد الجزر وانا الضياء تخيفني دجن واخاف ان ساضيع في الفجر يانوم كل عوالمي حجب ولو التقيتك ذابت الحجب و انثال من سهري علي سهري ينبوعك المتثاءب الرطب اثملت بين جوانحي املا ماكنت اعلم انه امل مثل الفراشة عاد يحبسها دوح بذاءب طله خضل لولا خفوق جناحها غفلت بيض الازاهر عنه والمقل انا من ظلالك بين اودية عذراء كل سهادها عشب هام الضباب علي جوانبها طل الوشاح كنجمة تخبو  انا كوكب ظمان ترعشه نطف مءرجة من السحر انا غير جسمي عالمي حلم بكر الظلال ولمحه عمري قلبي تغرب عن احبته وانسل من نغماته وتري فاذا لثمت فغير خادعة بات لكل مخادع تصبو واذا شدوت ارن في افق عبر السماء غناءي العذب  هو يافءادي طيفها مسحت عنه التراب انامل الغسق هو غير تلك اما تري القا هو من دماءك انت من حرقي هو غيرها غدرت وبادلني حبي و ضمد بالسنا افقي ومن المهازل ان يري امدا بين الخيانة و الهوي  هدب اين العوالم كيف غيرها نوم يرف وخاطر صب  خفقت ذواءبها علي شفتي و سني فاسكر عطرها نفسي نهر من النفحات ارشفني ريحا تريب مجامر الغلس فكان نايا ضمخته يدا اذار ناغم ليلة العرس فغفا و ما زالت ملاحنه ملء الفضاء يعيدها الحب او ان سوسنة يراقصها رجع الغناء بشعرها تربو  ياقبلة اخذت علي عجل افدي بعمري ذلك العجلا الشعر ستر بالظلال فمي فهوي علي الوجنات واشتعلا فعلي جوانبهن منه سنا يدعوه من جهل الهوي خجلا فضح احمرارك ياخدود فما زال يفضحني بما يحبو هو طفلك الاهي ينازعه ابدا الي زهراتك العب  يا جسم ذاك الطيف ايا شبحا من ذكرياتي يا هوي خدعا لعناتي الحنقات ما برحت تعتاد خدرك و الظلام معا خفقت باجنحة الغراب علي عينيك تنشر حولك الفزعا الصبح صبحك ضحك شامتة دام و ليلك مضجع ينبو و اذا هلكت غدا فلا تجدي قبرا و مزق صدرك الذءب  و البوم يملا عشه نتفا من شعرك المتعفر الضجر و يعود ثغرك لذباب لقي و يداك مثقلتان بالحجر لا تدفعان اذاه عن شفة بالامس اخرس لغوها و تري و ليسق من دمك الخبث غدا دوح تعش فوقه الغرب تاوي الصلال الي جوانبه غرثي و يعوي تحته الكلب  ويعود من خشباته نزق جان بمقبض خنجر دام ويعد منه سرير زانية تهوي فتثقله باثام وتظل اعواد المشانق من اعواده كسيت باجسام حتي اذا عصف الذبول به وهوي عليه المعول العضب كان الوقود لقدر ساحرة بين المقابر شانها القشب\n",
      " علي مقلتيك ارتشفت النجوم وعانقت امالي الايبة وسابقت حتي جناح الخيال بروحي الي روحك الواثبة اطلت فكانت سنا ذاءبا بعينيك في بسمة ذاءبة  انت التي ردتها مناي اناشيد تحت ضياء القمر تغني بها في ليالي الربيع فتحلم ازهاره بالمطر ويمضي صداها يهز الضياء ويغفو علي الزورق المنتظر  خذي الكاس بلي صداك العميق بما ارتج في قاعها من شراب خذي الكاس لا جف ذاك الرحيق و الا صدي هامس في القرار الا ليتني ما سقيت التراب  خذي الكاس اني زرعت الكروم علي قبر ذاك الهوي الخاسر فاعراقها تستعيد الشراب وتشتفه من يد العاصر خذي الكاس اني نسيت الزمان فما في حياتي سوي حاضر  وكان انتظار لهذا الهوي جلوسي علي الشاطيء المقفر وارسال طرفي يجوب العباب ويرتد عن افقه الاسمر الي ان اهل الشراع الضحوك وقالت لك الامنيات انظري  انكرت حتي هواك الجوج وقلبي واشواقك العارمة وضلت في وهدة الكبرياء صداها فيا لك من ظالمة تجنيت حتي حسبت النعاس ذبولا علي الزهرة الناءمة  اتنسين تحت التماع النجوم خطانا وانفاسنا الواجفة وكيف احتضنا صدي في القلوب تغني به القبلة الراجفة صدي لج احتراق الشفاة وما زال في غيهب العاطفة  ورانت علي الاعين الوامقات ظلال من القبلة الناءية تنادي بها رغبة في الشفاة ويمنعها الشك والواشية فترتج عن ضغطة في اليدين جكعنا بها الدهر في ثانية  شقيقة روحي الا تذكرين نداء سيبقي يجوب السنين وهمس من الانجم الحالمات يهز التماعاتها بالرنين تسل من فجوة في الستار اليك وقال الا تذكرين  تعالي فما زال في مقلتي سنا ماج فيه اتقاد الفءاد كما لاح في الجدول المطمءن خيال الظي والنجوم البعاد فلا تزعمي ان هذا جليد ولا تزعمي ان هذا رماد\n",
      "اساطير من حشرجات الزمان نسيج اليد البالية رواها ظلام من الهاوية وغني بها ميتان اساطير كالبيد ماج سراب عليها وشقت بقايا شهاب وابصرت فيها بريق النضار يلاقي سدي من ظلال الرغيف وابصرتني والستار الكثيف يواريك عني فضاع انتظار وخابت مني وانتهي عاشقان  اساطير مثل المدي القاسيات تلاوينها من دم الباءسين فكم اومضت في عيون الطغاة بما حملت من غبار السنين يقولون وحي السماء فلو يسمع الانبياء لما قهقهت ظلمة الهاوية باسطورة بالية تجر القرون بمركبة من لظي في جنون لظي كالجنون  وهذا الغرام الجوج ايريد من لمسة باردة علي اصبع من خيال الثلوج واسطورة باءدة وعرافة اطلقت في الرمال بقايا سءال وعينين تستطلعان الغيوب وتستشرقان الدروب فكان ابتهال وكانت صلاة تغفر وجه الالة وتحنو عليه انطباق الشفاة  تعالي فما زال نجم المساء يذيب السنا في النهار الغريق ويغشي سكون الطريق بلونين من ومضة واطفاء وهمس الهول الثقيل بدفء الشذي واكتءاب الغروب يذكرني بالرحيل شراع خلال التحايا يذوب وكف تلوح يا لعذاب  تعالي فما زال لون السحاب حزينا يذكرني بالرحيل رحيل تعالي تعالي نذيب الزمان وساعة في عناق طويل ونصبح بالارجوان شراعا وراء المدي ونسي الغدا علي صدرك الدافء العاطر كتهويمة الشاعر تعالي فملء الفضاء صدي هامس بالقاء يوسوس دون انتهاء  علي مقلتيك انتظار بعيد وشيء يءيد ظلال يغمغم في جانبيها سءال وشوق حزين يريد اعتصار السراب وتمزيق اسطورة الاولين فيا لعذاب جناحان خلف الحجاب شراع وغمغمة بالوداع \n",
      "والتف حولك ساعداي ومال جيدك في اشتهاء كالزهرة الوسني فما احست الا والشفاة فوق الشفاة ولمساء عطر يضوع فتسكرين به واسكر من شذاه في الجيد والفم والذراع فاغيب في افق بعيد مثلما ذاب الشراع في ارجوان الشاطء الناءي واوغل في مداه شفتاك في شفتي عالقتان والنجم الضءيل يلقي سناه علي بقايا راعشات من عناق ثم ارتخت عني يداك واطبق الصمت الثقيل يا نشوة عبري واعفاء علي ظل الفراق حلوا كاغماء الفراشة من ذهول وانتشاء دوما الي غير انتهاء يا همسة فوق الشفاة ذابت فكانت شبه اه يا سكرة مثل ارتجافات الغروب الهاءمات رانت كما سكن الجناح وقد تناءي في الفضاء غرقي الي غير انتهاء مثل النجوم الافلات لا لن تراني لن اعود هيهات لكن الوعود تبقي تلح فخف انت وسوف اتي في الخيال يوما اذا ما جءت انت وربما سال الضياء فوق الوجوه الضاحكات وقد نسيت وما يزال بين الاراءك موضع خال يحدق في غباء هذا الفراغ اما تحس به يحدق في وجوم هذا الفراغ انا الفراغ فخف انت لكي يدوم هذا هواليوم الاخير واحسرتاه اتصدقين الن تخف الي لقاء هذا هو اليوم الاخير فليته دون انتهاء ليت الكواكب لا تسير والساعة العجلي تنام علي الزمان فلا تفيق خلفتني وحدي اسير الي السراب بلا رفيق يا لعذاب اما بوسعك ان تقولي يعجزون عنا فماذا يصنعون لو اني حان القاء فاقتادني نجم المساء في غمرة لا استفيق الا وانت خصري تحت اضواء الطريق ليل ونافذة تضاء تقول انك تسهرين اني احسك تهمسين في ذلك الصمت الميت الن تخف الي لقاء ليل ونافذة تضاء تغشي رءاي وانت فيها ثم ينحل الشعاع في ظلمة اليل العميق ويلوح ظلك من بعيد وهو يومء بالوداع واظل وحدي في الطريق\n",
      " اطلي علي طرفي الدامع خيالا من الكوكب الساطع ظلا من الاغصن الحالمات علي ضفة الجدول الوادع وطوفي اناشي\n"
     ]
    }
   ],
   "source": [
    "print(data[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "\n",
      " ءابةتثجحخدذرزسشصضطظعغفقكلمنهوي\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, 'ء': 2, 'ا': 3, 'ب': 4, 'ة': 5, 'ت': 6, 'ث': 7, 'ج': 8, 'ح': 9, 'خ': 10, 'د': 11, 'ذ': 12, 'ر': 13, 'ز': 14, 'س': 15, 'ش': 16, 'ص': 17, 'ض': 18, 'ط': 19, 'ظ': 20, 'ع': 21, 'غ': 22, 'ف': 23, 'ق': 24, 'ك': 25, 'ل': 26, 'م': 27, 'ن': 28, 'ه': 29, 'و': 30, 'ي': 31}\n",
      "{0: '\\n', 1: ' ', 2: 'ء', 3: 'ا', 4: 'ب', 5: 'ة', 6: 'ت', 7: 'ث', 8: 'ج', 9: 'ح', 10: 'خ', 11: 'د', 12: 'ذ', 13: 'ر', 14: 'ز', 15: 'س', 16: 'ش', 17: 'ص', 18: 'ض', 19: 'ط', 20: 'ظ', 21: 'ع', 22: 'غ', 23: 'ف', 24: 'ق', 25: 'ك', 26: 'ل', 27: 'م', 28: 'ن', 29: 'ه', 30: 'و', 31: 'ي'}\n",
      "[3, 26, 15, 26, 3, 27, 1, 21, 26, 31, 25, 27]\n",
      "السلام عليكم\n"
     ]
    }
   ],
   "source": [
    "ctoi = {k:i for i, k in enumerate(chars)}\n",
    "itoc = {k:v for v,k in ctoi.items()}\n",
    "\n",
    "print(ctoi)\n",
    "print(itoc)\n",
    "\n",
    "encode  = lambda x:[ctoi[c] for c in x]\n",
    "decode = lambda x: ''.join([itoc[c] for c in x])\n",
    "\n",
    "print(encode('السلام عليكم'))\n",
    "print(decode(encode('السلام عليكم')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1097608]) torch.int64\n",
      "tensor([21, 31, 28,  3, 25,  1, 22,  3,  4,  6,  3,  1, 28, 10, 31])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_enc = torch.tensor(encode(data), dtype=torch.long)\n",
    "print(data_enc.shape, data_enc.dtype)\n",
    "\n",
    "print(data_enc[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into: train, val\n",
    "n = int(0.9 * len(data_enc))   \n",
    "train_data = data_enc[:n]\n",
    "val_data = data_enc[n:]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " when input is tensor([21]), the target is 31\n",
      " when input is tensor([21, 31]), the target is 28\n",
      " when input is tensor([21, 31, 28]), the target is 3\n",
      " when input is tensor([21, 31, 28,  3]), the target is 25\n",
      " when input is tensor([21, 31, 28,  3, 25]), the target is 1\n",
      " when input is tensor([21, 31, 28,  3, 25,  1]), the target is 22\n",
      " when input is tensor([21, 31, 28,  3, 25,  1, 22]), the target is 3\n",
      " when input is tensor([21, 31, 28,  3, 25,  1, 22,  3]), the target is 4\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "eval_iterations = 10\n",
    "eval_interval = 1000\n",
    "total_steps = 10000\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f' when input is {context}, the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "# Note that this training examples would be un-rolled into more examples\n",
    "block_size = 8\n",
    "batch_size  = 4\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    index = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i: i+block_size] for i in index])\n",
    "    y = torch.stack([data[i+1: i+block_size+1] for i in index])\n",
    "    return x.to(device),y.to(device)\n",
    "    \n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "# This creates 4 * 8 matrix which has 32 training example   \n",
    "print(xb.shape)\n",
    "print(yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calc_losses():\n",
    "    out = {}\n",
    "\n",
    "    m.eval()\n",
    "    for split in ['train','val']:\n",
    "        loss_sum = 0.0\n",
    "        for i in range(eval_iterations):\n",
    "\n",
    "            xs, ys = get_batch(split=split)\n",
    "            _ , loss = m(xs,ys)\n",
    "            loss_sum += loss\n",
    "\n",
    "        out[split] = loss_sum/eval_iterations\n",
    "    \n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(num_chars):\n",
    "    st = torch.zeros((1,1), dtype=torch.long).to(device)\n",
    "    return decode(m.generate(st,num_chars)[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Bi-gram model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size,vocab_size)\n",
    "    def forward(self, idx, targets = None):\n",
    "        loss = None\n",
    "        logits = self.embed(idx)\n",
    "        # print(logits.shape, targets.shape)\n",
    "        \n",
    "        if not targets == None:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    def generate(self, context, max_no):\n",
    "        size = context.shape[1]\n",
    "\n",
    "        for _ in range(max_no):\n",
    "            cur = context[:, -size:]  # B, T\n",
    "            # print('1',cur.shape)\n",
    "            logits, _ = self(cur) # B*T , C \n",
    "            # print('2,',logits.shape)\n",
    "\n",
    "            ## This works   for any context size, we average the logits for all characters so that we can do softmax on them\n",
    "            # logits = logits.mean(1)\n",
    "\n",
    "            ### THis is the method they used in the video, they only took the logits of the last character to predict the next one\n",
    "            logits = logits[:,-1,:]\n",
    "\n",
    "\n",
    "            \n",
    "            # print('3,',logits.shape)\n",
    "            props = F.softmax(logits, dim=1)# B*T , C\n",
    "            # print('soft max',props.shape)\n",
    "            # props = props.squeeze(0).view(-1, size) # B,T\n",
    "            # print('probs 1',props.shape)\n",
    "            next_char = torch.multinomial(props, 1)  # B,1\n",
    "            # print(next_char.shape)\n",
    "            context = torch.cat((context, next_char), dim =1) # B, T+1\n",
    "        return context\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = BigramModel(vocab_size).to(device)\n",
    "# # out,loss = m(xb,yb)\n",
    "# # print(out)\n",
    "# # print(out.shape)\n",
    "# # print( loss)\n",
    "# print(next(m.parameters()).device)\n",
    "# g = m.generate(xb, 1)\n",
    "# print(g.shape)\n",
    "# # print(list(xb[0].tolist()))\n",
    "# print(decode(list(xb[0].tolist())))\n",
    "# print(decode(list(g[0].tolist())))\n",
    "\n",
    "# st = torch.zeros((1,1), dtype=torch.long)\n",
    "# print(decode(m.generate(st,100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 3.8451, val loss 3.8219\n",
      "step 1000: train loss 3.8501, val loss 3.7318\n",
      "step 2000: train loss 3.7235, val loss 3.7012\n",
      "step 3000: train loss 3.6994, val loss 3.6352\n",
      "step 4000: train loss 3.5503, val loss 3.6860\n",
      "step 5000: train loss 3.6076, val loss 3.5842\n",
      "step 6000: train loss 3.4867, val loss 3.5514\n",
      "step 7000: train loss 3.4241, val loss 3.3968\n",
      "step 8000: train loss 3.3979, val loss 3.4107\n",
      "step 9000: train loss 3.3279, val loss 3.4004\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "for step in range(total_steps):\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        losses = calc_losses()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb,yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb,yb)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ةبسشااض ررداييضغفضحوخزيدمقدعدعءاخشب ضيفمغعظطءجدشقم رهاءصذب صذبولشدوقخعزفيتجتذبووبضقدنشهطنعمظجرتضغربت\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gen(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START IN ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C = 4,8,2\n",
    "torch.manual_seed(1337)\n",
    "x=  torch.randn(B,T,C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_X = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for i in range(T):\n",
    "        temp = x[b,:i+1,:]\n",
    "        new_X[b,i] = temp.mean(0)\n",
    "\n",
    "print(x[0])\n",
    "print(new_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor(9.1398) tensor(9.1398)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(T,T))\n",
    "mask =  mask /mask.sum(1, keepdim=True)\n",
    "# print(mask)\n",
    "\n",
    "# mask = mask.expand(B,T,T)\n",
    "mask.shape\n",
    "new_X_2 = mask @ x\n",
    "# print(new_X_2)\n",
    "# print(new_X)\n",
    "print(torch.equal(new_X,new_X_2))\n",
    "print(new_X_2.sum(), new_X.sum())\n",
    "torch.allclose(new_X, new_X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using softmax\n",
    "B,T,C = 4,8,32\n",
    "torch.manual_seed(1337)\n",
    "x=  torch.randn(B,T,C)\n",
    "head_size = 16\n",
    "q = nn.Linear(C,head_size, bias=False)\n",
    "k = nn.Linear(C,head_size, bias=False)\n",
    "v = nn.Linear(C,head_size, bias=False)\n",
    "\n",
    "query = q(x)\n",
    "key = k(x)\n",
    "value = v(x)\n",
    "\n",
    "wei = query @ key.transpose(-2,-1)\n",
    "mask = torch.tril(torch.ones(T,T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(mask == 0,float('-inf'))\n",
    "wei = torch.softmax(wei,2)\n",
    "\n",
    "out = wei @ value\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5877, 0.4123, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4457, 0.2810, 0.2733, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2220, 0.7496, 0.0175, 0.0109, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0379, 0.0124, 0.0412, 0.0630, 0.8454, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5497, 0.2187, 0.0185, 0.0239, 0.1831, 0.0062, 0.0000, 0.0000],\n",
       "        [0.2576, 0.0830, 0.0946, 0.0241, 0.1273, 0.3627, 0.0507, 0.0000],\n",
       "        [0.0499, 0.1052, 0.0302, 0.0281, 0.1980, 0.2657, 0.1755, 0.1474]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "jupyter-eg-kernel-slurm-py37-condatest-1h0khvpjs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
