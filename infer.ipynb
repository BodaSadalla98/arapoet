{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e62e8d6-449b-46eb-8ab7-5dea5b158ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Using device:', device)\n",
    "\n",
    "from transformers import GPT2TokenizerFast, pipeline\n",
    "#for base and medium\n",
    "from transformers import GPT2LMHeadModel\n",
    "#for large and mega\n",
    "# pip install arabert\n",
    "from arabert.aragpt2.grover.modeling_gpt2 import GPT2LMHeadModel\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8de0f7-894e-406f-87e2-b4321ae488e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman.atef\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d694ae-cc90-4cb9-b367-18a20bd20e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-05-21 10:12:24,668.668 root] Model provided is not in the accepted model list. Preprocessor will default to a base Arabic preprocessor\n",
      "Some weights of the model checkpoint at boda/ara-poet/output/checkpoint-254940 were not used when initializing GPT2LMHeadModel: ['transformer.ln_f.bias', 'transformer.ln_f.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at boda/ara-poet/output/checkpoint-254940 and are newly initialized: ['transformer.emb_norm.bias', 'transformer.emb_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME='boda/ara-poet/output/checkpoint-254940'\n",
    "arabert_prep = ArabertPreprocessor(model_name=MODEL_NAME)\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(MODEL_NAME)\n",
    "generation_pipeline = pipeline(\"text-generation\",model=model,tokenizer=tokenizer, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aede8b80-7a62-4c96-ae61-c12e70f2bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at boda/ara-poet/output_tiny/checkpoint-9956 were not used when initializing GPT2LMHeadModel: ['transformer.ln_f.bias', 'transformer.ln_f.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at boda/ara-poet/output_tiny/checkpoint-9956 and are newly initialized: ['transformer.emb_norm.bias', 'transformer.emb_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME='boda/ara-poet/output_tiny/checkpoint-9956'\n",
    "tiny_model = GPT2LMHeadModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "tiny_generation_pipeline = pipeline(\"text-generation\",model=model,tokenizer=tokenizer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e5e5fd9-6f1c-41c0-859b-38ee18c676e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حملناك يا مصر بين الحنايا وبين الضلوع وفوق الجبين عشقناك صدرا رعانا بدفء وان طال فينا زمان الحنين فلا تحزني من زمان جحود اذقناك فيه هموم السنين تركنا دماءك\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'حملناك يا مصر بين الحنايا وبين الضلوع وفوق الجبين عشقناك صدرا رعانا بدفء وان طال فينا زمان الحنين فلا تحزني من زمان جحود اذقناك فيه هموم السنين تركنا دماءك بن بن الم بن والق بن بن بن'}]\n",
      "[{'generated_text': 'حملناك يا مصر بين الحنايا وبين الضلوع وفوق الجبين عشقناك صدرا رعانا بدفء وان طال فينا زمان الحنين فلا تحزني من زمان جحود اذقناك فيه هموم السنين تركنا دماءك بن بن الم بن بن بص بن بن'}]\n"
     ]
    }
   ],
   "source": [
    "# text=\"كان يا ما كان في قديم\"\n",
    "text = \"سأخبرك بكل ما يجول في خاطري\"\n",
    "text = \"حملناك يا مصر بين الحنايا وبين الضلوع وفوق الجبين عشقناك صدرا رعانا بدفء وان طال فينا زمان الحنين فلا تحزني من زمان جحود اذقناك فيه هموم السنين تركنا دماءك\"\n",
    "text_clean = arabert_prep.preprocess(text)\n",
    "print(text_clean)\n",
    "print(generation_pipeline(text_clean))\n",
    "print(tiny_generation_pipeline(text_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e96a22-fbac-4215-a2dd-34c3f6b6daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
