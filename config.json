{
    "model_name_or_path": "gpt2-large",
    "model_type": "gpt2",
    "train_file": "data.txt",
    "validation_file": "tiny_data.txt",
    "block_size": 128,
    "preprocessing_num_workers": 32,
    "output_dir": "output",
    "do_train": "true",
    "do_eval": "true",
    "overwrite_output_dir": "true",
    "num_train_epochs": 3000.0,
    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,
    "save_strategy": "epoch",
    "evaluation_strategy": "epoch",
    "save_total_limit": 5
}